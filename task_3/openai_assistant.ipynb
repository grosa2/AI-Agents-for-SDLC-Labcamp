{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Building your first OpenAI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import  AsyncOpenAI\n",
    "from openai.types.beta import Thread\n",
    "from openai.types.beta.threads import Run\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Assistant class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssistantResult(BaseModel):\n",
    "    response: str\n",
    "    thread_id: str\n",
    "\n",
    "class MaxTurnsReachedException(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Reached maximum number of turns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, assistant_id: str, tools: Dict[str, callable]):\n",
    "        self.client = AsyncOpenAI()\n",
    "        self.assistant_id = assistant_id\n",
    "        self.assistant = None\n",
    "        self.tools = tools\n",
    "    \n",
    "    async def retrieve_assistant(self):\n",
    "        if self.assistant is None:\n",
    "            self.assistant = await self.client.beta.assistants.retrieve(self.assistant_id)\n",
    "        return self.assistant\n",
    "    \n",
    "    async def run(self, query: str, thread_id: str = None, max_turns: int = 5) -> AssistantResult:\n",
    "        await self.retrieve_assistant()\n",
    "\n",
    "        print(f\"Running assistant with thread_id {thread_id}\")\n",
    "\n",
    "        if(thread_id is None):\n",
    "            thread: Thread = await self.client.beta.threads.create()\n",
    "            print(f\"Created new thread with id {thread.id}\")\n",
    "        else:\n",
    "            thread: Thread = await self.client.beta.threads.retrieve(thread_id)\n",
    "            print(f\"Retrieved thread with id {thread.id}\")\n",
    "        \n",
    "        print(f\"Sending query to thread {thread.id}: {query}\")\n",
    "        await self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id, role=\"user\", content=query\n",
    "        )\n",
    "\n",
    "        run: Run = await self.client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant_id,\n",
    "        )\n",
    "\n",
    "        for turn in range(max_turns):\n",
    "\n",
    "            # Fetch the last message from the thread\n",
    "            messages = await self.client.beta.threads.messages.list(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                order=\"desc\",\n",
    "                limit=1,\n",
    "            )\n",
    "            # print(f\"Fetched last message from thread {thread.id}: {messages}\")\n",
    "\n",
    "            # Check for the terminal state of the Run.\n",
    "            # If state is \"completed\", exit agent loop and return the LLM response.\n",
    "            if run.status == \"completed\":\n",
    "                print(f\"Run completed for thread {thread.id}\")\n",
    "                assistant_res: str = next(\n",
    "                    (\n",
    "                        content.text.value\n",
    "                        for content in messages.data[0].content\n",
    "                        if content.type == \"text\"\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                return AssistantResult(thread_id=thread.id, response=assistant_res)\n",
    "            \n",
    "            # If state is \"requires_action\", function calls are required. Execute the functions and send their outputs to the LLM.\n",
    "            if run.status == \"requires_action\":\n",
    "                func_tool_outputs = []\n",
    "\n",
    "                # LLM can ask for multiple functions to be executed. Execute all function calls in loop and\n",
    "                # append the results into `func_tool_outputs` list.\n",
    "                for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                    # parse the arguments required for the function call from the LLM response\n",
    "                    args = (\n",
    "                        json.loads(tool.function.arguments)\n",
    "                        if tool.function.arguments\n",
    "                        else {}\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        print(\"Requiring function call {} with args {} for thread {}\".format(tool.function.name, args, thread.id))\n",
    "                        func_output = await self.tools[tool.function.name](**args)\n",
    "                        print(\"Function outputs: {}\".format(func_output))\n",
    "                    except Exception as e:\n",
    "                        print(\"Error in running function {}: {}\".format(tool.function.name, e))\n",
    "                        func_output = f'Error in running function {tool.function.name}: {e}'\n",
    "\n",
    "                    # OpenAI needs the output of the function call against the tool_call_id\n",
    "                    func_tool_outputs.append(\n",
    "                        {\"tool_call_id\": tool.id, \"output\": str(func_output)}\n",
    "                    )\n",
    "\n",
    "                # Submit the function call outputs back to OpenAI\n",
    "                run = await self.client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "                    thread_id=thread.id, run_id=run.id, tool_outputs=func_tool_outputs\n",
    "                )\n",
    "\n",
    "                # Continue the agent loop.\n",
    "                # Agent will check the output of the function output submission as part of next iteration.\n",
    "                continue\n",
    "\n",
    "            # Handle errors if terminal state is \"failed\"\n",
    "            else:\n",
    "                if run.status == \"failed\":\n",
    "                    print(\n",
    "                        f\"OpenAIFunctionAgent turn-{turn+1} | Run failure reason: {run.last_error}\"\n",
    "                    )\n",
    "\n",
    "                raise Exception(\n",
    "                    f\"Failed to generate text due to: {run.last_error}\"\n",
    "                )\n",
    "        \n",
    "        # Raise error if turn-limit is reached.\n",
    "        await self.client.beta.threads.runs.cancel(run.id,thread_id=thread_id)\n",
    "        raise MaxTurnsReachedException()\n",
    "    \n",
    "    async def cancel_thread_run(self, thread_id: str):\n",
    "        thread: Thread = await self.client.beta.threads.retrieve(thread_id)\n",
    "        run: Run = await self.client.beta.threads.runs.list(thread_id=thread.id).data[0]\n",
    "\n",
    "        await self.client.beta.threads.runs.cancel(run.id,thread_id=thread_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Assistant Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calculate(what: str) -> float:\n",
    "    \"\"\"\n",
    "    e.g. calculate: 4 * 7 / 3\n",
    "    Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary.\n",
    "    \"\"\"\n",
    "    return eval(what)\n",
    "\n",
    "\n",
    "async def average_price_per_weight(name: str) -> str:\n",
    "    \"\"\"\n",
    "    e.g. average_price_per_weight: mortadella\n",
    "    returns average price per weight of the provided cold cut (e.g. mortadella, prosciutto cotto, etc.)\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    if name == \"bresaola\":\n",
    "        return \"Bresaola has an average price of about 40 euros per kilogram.\"\n",
    "    elif name == \"prosciutto crudo\" or name == \"prosciutto\":\n",
    "        return \"Prosciutto crudo (cured ham) has an average price of about 30 euros per kilogram.\"\n",
    "    elif name == \"prosciutto cotto\":\n",
    "        return \"Prosciutto cotto (cooked ham) has an average price of about 15 euros per kilogram.\"\n",
    "    elif name == \"mortadella\":\n",
    "        return \"Mortadella has an average price of about 12 euros per kilogram.\"\n",
    "    elif name == \"pancetta\":\n",
    "        return \"Pancetta has an average price of about 18 euros per kilogram.\"\n",
    "    else:\n",
    "        return \"Unknown product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function schemas - copy and paste into OpenAI Playground\n",
    "#\n",
    "\n",
    "# {\n",
    "#   \"name\": \"calculate\",\n",
    "#   \"description\": \"Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary.\",\n",
    "#   \"strict\": true,\n",
    "#   \"parameters\": {\n",
    "#     \"type\": \"object\",\n",
    "#     \"required\": [\n",
    "#       \"what\"\n",
    "#     ],\n",
    "#     \"properties\": {\n",
    "#       \"what\": {\n",
    "#         \"type\": \"string\",\n",
    "#         \"description\": \"A string expression representing the calculation to perform (e.g. '4 * 7 / 3')\"\n",
    "#       }\n",
    "#     },\n",
    "#     \"additionalProperties\": false\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# {\n",
    "#   \"name\": \"average_price_per_weight\",\n",
    "#   \"description\": \"Returns average price per weight of the provided cold cut (e.g. mortadella, prosciutto cotto, etc.)\",\n",
    "#   \"strict\": true,\n",
    "#   \"parameters\": {\n",
    "#     \"type\": \"object\",\n",
    "#     \"required\": [\n",
    "#       \"name\"\n",
    "#     ],\n",
    "#     \"properties\": {\n",
    "#       \"name\": {\n",
    "#         \"type\": \"string\",\n",
    "#         \"description\": \"The name of the cold cut for which the average price per weight is requested\"\n",
    "#       }\n",
    "#     },\n",
    "#     \"additionalProperties\": false\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the OpenAI Assistant using the OpenAI Playground\n",
    "\n",
    "1. Navigate to [OpenAI Assistant Playground](https://platform.openai.com/playground/assistants)\n",
    "2. Create a new Assistant and name following the format: `<name_first_letter>_<surname>_first_agent`\n",
    "3. Define the System Instructions\n",
    "4. Select gpt-4o-mini as the model\n",
    "5. Generate a new Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# System prompt - copy and paste into OpenAI Playground\n",
    "#\n",
    "\n",
    "# # Task\n",
    "# You are SalumiereGPT, an helpful assistant for a supermarket. Your goal is to calculate the price of the requested food by the user.\n",
    "# You have several tools available that help you to get the prices and calculate the final cost. \n",
    "\n",
    "# # Output\n",
    "# - Provide the price detail if multiple items are requested\n",
    "# - Keep your answer concise\n",
    "\n",
    "# # Example session:\n",
    "# Question: How much is 1kg of mortadella?\n",
    "# Thought: I should get the mortadella price using average_price_per_weight\n",
    "# Action: average_price_per_weight: mortadella\n",
    "\n",
    "# (You will be called again with this:)\n",
    "\n",
    "# Observation: Mortadella has an average price of about 12 euros per kilogram.\n",
    "\n",
    "# (You then output:)\n",
    "\n",
    "# 1kg of mortadella is 12 euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT_ID = \"<YOUR_ASSISTANT_ID>\"\n",
    "ASSISTANT_ID = \"asst_dbf562R2LG7PaYwzSDTgnqW0\"\n",
    "\n",
    "TOOLS = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_price_per_weight\": average_price_per_weight\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the assistant instance\n",
    "assistant = Assistant(ASSISTANT_ID, TOOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running assistant with thread_id None\n",
      "Created new thread with id thread_ZUyTXDX5rkla5uWB1ztqwK80\n",
      "Sending query to thread thread_ZUyTXDX5rkla5uWB1ztqwK80: Hi, who are you?\n",
      "Run completed for thread thread_ZUyTXDX5rkla5uWB1ztqwK80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantResult(response='I am SalumiereGPT, your helpful assistant for supermarket queries, specifically related to food prices. How can I assist you today?', thread_id='thread_ZUyTXDX5rkla5uWB1ztqwK80')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant.run(query=\"Hi, who are you?\", max_turns=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running assistant with thread_id None\n",
      "Created new thread with id thread_es51baxcxQHe1yeU0Vqb3YGD\n",
      "Sending query to thread thread_es51baxcxQHe1yeU0Vqb3YGD: How much are 76g of mortadella?\n",
      "Requiring function call average_price_per_weight with args {'name': 'mortadella'} for thread thread_es51baxcxQHe1yeU0Vqb3YGD\n",
      "Function outputs: Mortadella has an average price of about 12 euros per kilogram.\n",
      "Requiring function call calculate with args {'what': '12 * 76 / 1000'} for thread thread_es51baxcxQHe1yeU0Vqb3YGD\n",
      "Function outputs: 0.912\n",
      "Run completed for thread thread_es51baxcxQHe1yeU0Vqb3YGD\n",
      "###########################################\n",
      "\n",
      "Thread ID: thread_es51baxcxQHe1yeU0Vqb3YGD\n",
      "\n",
      "76g of mortadella is approximately 0.91 euros.\n"
     ]
    }
   ],
   "source": [
    "question = \"How much are 76g of mortadella?\"\n",
    "\n",
    "res = await assistant.run(query=question, max_turns=5)\n",
    "print(\"###########################################\\n\")\n",
    "print(f\"Thread ID: {res.thread_id}\\n\")\n",
    "print(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running assistant with thread_id None\n",
      "Created new thread with id thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Sending query to thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP: I need 200g of pancetta, 150g of prosciutto crudo, and 45g of bresaola. How much is it?\n",
      "Requiring function call average_price_per_weight with args {'name': 'pancetta'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: Pancetta has an average price of about 18 euros per kilogram.\n",
      "Requiring function call average_price_per_weight with args {'name': 'prosciutto crudo'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: Prosciutto crudo (cured ham) has an average price of about 30 euros per kilogram.\n",
      "Requiring function call average_price_per_weight with args {'name': 'bresaola'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: Bresaola has an average price of about 40 euros per kilogram.\n",
      "Requiring function call calculate with args {'what': '0.2 * 18'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: 3.6\n",
      "Requiring function call calculate with args {'what': '0.15 * 30'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: 4.5\n",
      "Requiring function call calculate with args {'what': '0.045 * 40'} for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "Function outputs: 1.7999999999999998\n",
      "Run completed for thread thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "###########################################\n",
      "\n",
      "Thread ID: thread_0Wh0IzXPF8ij8ZXIKvrHnVHP\n",
      "\n",
      "The total cost is as follows:\n",
      "\n",
      "- 200g of pancetta: 3.60 euros\n",
      "- 150g of prosciutto crudo: 4.50 euros\n",
      "- 45g of bresaola: 1.80 euros\n",
      "\n",
      "Total: 3.60 + 4.50 + 1.80 = 9.90 euros.\n"
     ]
    }
   ],
   "source": [
    "question = \"I need 200g of pancetta, 150g of prosciutto crudo, and 45g of bresaola. How much is it?\"\n",
    "\n",
    "res = await assistant.run(query=question, max_turns=5)\n",
    "print(\"###########################################\\n\")\n",
    "print(f\"Thread ID: {res.thread_id}\\n\")\n",
    "print(res.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-labcamp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
