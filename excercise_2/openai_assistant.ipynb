{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Building your first OpenAI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import logging\n",
    "from openai import  AsyncOpenAI\n",
    "from openai.types.beta import Thread\n",
    "from openai.types.beta.threads import Run\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Assistant class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssistantResult(BaseModel):\n",
    "    response: str\n",
    "    thread_id: str\n",
    "\n",
    "class MaxTurnsReachedException(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Reached maximum number of turns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, assistant_id: str, tools: Dict[str, callable]):\n",
    "        self.client = AsyncOpenAI()\n",
    "        self.assistant_id = assistant_id\n",
    "        self.assistant = None\n",
    "        self.tools = tools\n",
    "    \n",
    "    async def retrieve_assistant(self):\n",
    "        if self.assistant is None:\n",
    "            self.assistant = await self.client.beta.assistants.retrieve(self.assistant_id)\n",
    "        return self.assistant\n",
    "    \n",
    "    async def run(self, query: str, thread_id: str = None, max_turns: int = 5) -> AssistantResult:\n",
    "        await self.retrieve_assistant()\n",
    "\n",
    "        log.info(\"Running assistant with thread_id %s\", thread_id)\n",
    "\n",
    "        if(thread_id is None):\n",
    "            thread: Thread = await self.client.beta.threads.create()\n",
    "            log.info(\"Created new thread with id %s\", thread.id)\n",
    "        else:\n",
    "            thread: Thread = await self.client.beta.threads.retrieve(thread_id)\n",
    "            log.info(\"Retrieved thread with id %s\", thread.id)\n",
    "        \n",
    "        log.info(\"Sending query to thread %s\", thread.id)\n",
    "        await self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id, role=\"user\", content=query\n",
    "        )\n",
    "        log.info(\"Query sent to thread %s\", thread.id)\n",
    "\n",
    "        log.info(\"Creating and polling run for thread %s\", thread.id)\n",
    "        run: Run = await self.client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant_id,\n",
    "        )\n",
    "        log.info(\"Run created and polled for thread %s\", thread.id)\n",
    "\n",
    "        for turn in range(max_turns):\n",
    "\n",
    "            # Fetch the last message from the thread\n",
    "            log.info(\"Fetching last message from thread %s\", thread.id)\n",
    "            messages = await self.client.beta.threads.messages.list(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                order=\"desc\",\n",
    "                limit=1,\n",
    "            )\n",
    "            log.info(\"Fetched last message from thread %s\", thread.id)\n",
    "\n",
    "            # Check for the terminal state of the Run.\n",
    "            # If state is \"completed\", exit agent loop and return the LLM response.\n",
    "            if run.status == \"completed\":\n",
    "                log.info(\"Run completed for thread %s\", thread.id)\n",
    "                assistant_res: str = next(\n",
    "                    (\n",
    "                        content.text.value\n",
    "                        for content in messages.data[0].content\n",
    "                        if content.type == \"text\"\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                return AssistantResult(thread_id=thread.id, response=assistant_res)\n",
    "            \n",
    "            # If state is \"requires_action\", function calls are required. Execute the functions and send their outputs to the LLM.\n",
    "            if run.status == \"requires_action\":\n",
    "                log.info(\"Run requires action for thread %s\", thread.id)\n",
    "                func_tool_outputs = []\n",
    "\n",
    "                # LLM can ask for multiple functions to be executed. Execute all function calls in loop and\n",
    "                # append the results into `func_tool_outputs` list.\n",
    "                for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                    # parse the arguments required for the function call from the LLM response\n",
    "                    args = (\n",
    "                        json.loads(tool.function.arguments)\n",
    "                        if tool.function.arguments\n",
    "                        else {}\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        log.info(\"Running function %s with args %s for thread %s\", tool.function.name, args, thread.id)\n",
    "                        func_output = await self.tools[tool.function.name](**args)\n",
    "                        log.info(\"Function %s executed successfully for thread %s\", tool.function.name, thread.id)\n",
    "                    except Exception as e:\n",
    "                        log.error(\"Error in running function %s: %s\", tool.function.name, e)\n",
    "                        func_output = f'Error in running function {tool.function.name}: {e}'\n",
    "\n",
    "                    # OpenAI needs the output of the function call against the tool_call_id\n",
    "                    func_tool_outputs.append(\n",
    "                        {\"tool_call_id\": tool.id, \"output\": str(func_output)}\n",
    "                    )\n",
    "\n",
    "                # Submit the function call outputs back to OpenAI\n",
    "                log.info(\"Submitting function outputs for thread %s\", thread.id)\n",
    "                run = await self.client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "                    thread_id=thread.id, run_id=run.id, tool_outputs=func_tool_outputs\n",
    "                )\n",
    "                log.info(\"Function outputs submitted for thread %s\", thread.id)\n",
    "\n",
    "                # Continue the agent loop.\n",
    "                # Agent will check the output of the function output submission as part of next iteration.\n",
    "                continue\n",
    "\n",
    "            # Handle errors if terminal state is \"failed\"\n",
    "            else:\n",
    "                if run.status == \"failed\":\n",
    "                    log.error(\n",
    "                        f\"OpenAIFunctionAgent turn-{turn+1} | Run failure reason: {run.last_error}\"\n",
    "                    )\n",
    "\n",
    "                raise Exception(\n",
    "                    f\"Failed to generate text due to: {run.last_error}\"\n",
    "                )\n",
    "        \n",
    "        # Raise error if turn-limit is reached.\n",
    "        await self.client.beta.threads.runs.cancel(run.id,thread_id=thread_id)\n",
    "        raise MaxTurnsReachedException()\n",
    "    \n",
    "    async def cancel_thread_run(self, thread_id: str):\n",
    "        thread: Thread = await self.client.beta.threads.retrieve(thread_id)\n",
    "        run: Run = await self.client.beta.threads.runs.list(thread_id=thread.id).data[0]\n",
    "\n",
    "        await self.client.beta.threads.runs.cancel(run.id,thread_id=thread_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Assistant Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_current_temperature(location: str, unit: str):\n",
    "    return 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the OpenAI Assistant using the OpenAI Playground\n",
    "\n",
    "1. Navigate to [OpenAI Assistant Playground](https://platform.openai.com/playground/assistants)\n",
    "2. Create a new Assistant and name following the format: `<name_first_letter>_<surname>_first_assistant`\n",
    "3. Define the System Instructions\n",
    "4. Select gpt-4o-mini as the model\n",
    "5. Generate a new Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSISTANT_ID=\"<YOUR_ASSISTANT_ID>\"\n",
    "TOOLS = {\"get_current_temperature\": get_current_temperature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = Assistant(ASSISTANT_ID, TOOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"What is the temperature in New York?\"\n",
    "\n",
    "response = await assistant.run(query=input, max_turns=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"and in Paris?\"\n",
    "\n",
    "response = await assistant.run(query=input, thread_id=response.thread_id, max_turns=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
